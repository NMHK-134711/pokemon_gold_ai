import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import re

class LLMPlanner:
    def __init__(self, model_id: str = "meta-llama/Llama-3.1-8B-Instruct"):
        print(f"'{model_id}' 모델을 로딩합니다. 시간이 걸릴 수 있습니다...")
        
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.bfloat16
        )

        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_id,
            quantization_config=quantization_config,
            device_map="auto"
        )
        print("모델 로딩이 완료되었습니다.")

    def _create_prompt_messages(self, game_state: dict, main_task: str, available_skills: list) -> list:
        loc = game_state['location']
        player = game_state['player_info']
        party_list = game_state['party_info']['pokemon']
        party_str = ", ".join([f"Lv.{p['level']}" for p in party_list])

        current_situation = (
            f"현재 위치: 맵(Bank {loc['map_bank']}, ID {loc['map_id']}).\n"
            f"플레이어 정보: 돈 ${player['money']}, 배지 {player['johto_badges_count']}개.\n"
            f"파티 정보: {game_state['party_info']['count']}마리 ({party_str}).\n"
            f"주요 이벤트: {game_state['event_statuses']}"
        )
        skill_descriptions = "\n".join([f"- {skill.description}" for skill in available_skills])

        system_prompt = "You are an expert AI playing 'Pokémon Gold'. Your task is to choose the single best action from a given list to achieve the main objective. Respond using the specified format."
        user_prompt = (
            f"### Main Objective\n{main_task}\n\n"
            f"### Current Game State\n{current_situation}\n\n"
            f"### Available Actions\n{skill_descriptions}\n\n"
            "### Instructions\n"
            "1. Analyze the current game state and the main objective, then write your step-by-step reasoning in a 'Thought' section.\n"
            "2. Based on your reasoning, choose the single most optimal action from the 'Available Actions' list and write its exact description in a 'Decision' section.\n"
            "Format:\nThought: [Describe your reasoning step-by-step here]\nDecision: [Copy the chosen action description here]"
        )

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

    def choose_next_skill(self, game_state: dict, main_task: str, available_skills: list):
        messages = self._create_prompt_messages(game_state, main_task, available_skills)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

        # 1. [핵심] `apply_chat_template`이 딕셔너리가 아닌 'Tensor'를 반환하는 것을 전제로 합니다.
        #    따라서 `inputs` 변수를 `inputs_tensor`로 명명하여 텐서임을 명확히 합니다.
        inputs_tensor = self.tokenizer.apply_chat_template(
            messages,
            add_generation_prompt=True,
            return_tensors="pt"
        ).to(self.model.device) # 텐서이므로 바로 .to(device)를 호출할 수 있습니다.
        
        # 2. [수정] `inputs_tensor`를 `input_ids` 인자에 직접 전달합니다.
        #    이 방식으로는 attention_mask를 전달할 수 없어 경고가 발생할 수 있지만, 실행은 됩니다.
        outputs = self.model.generate(
            input_ids=inputs_tensor,
            max_new_tokens=256,
            do_sample=False,
            pad_token_id=self.tokenizer.eos_token_id
        )
        
        # 3. [수정] 프롬프트의 길이는 `inputs_tensor`의 shape에서 직접 가져옵니다.
        #    shape[0]은 배치 크기(1), shape[1]은 시퀀스 길이입니다.
        prompt_length = inputs_tensor.shape[1]
        response_text = self.tokenizer.decode(outputs[0][prompt_length:], skip_special_tokens=True)
        print(f"LLM 원본 응답:\n{response_text}")

        try:
            chosen_description = response_text.split('Decision:')[1].strip()
        except IndexError:
            chosen_description = ""
        
        best_match_skill = None
        for skill in available_skills:
            if skill.description in chosen_description:
                best_match_skill = skill
                break
        
        if best_match_skill:
            print(f"LLM 선택 (파싱): {best_match_skill.description}")
            return best_match_skill
        else:
            print("경고: LLM이 유효한 스킬을 선택하지 못했습니다. 기본 스킬을 반환합니다.")
            return available_skills[0]
        
    def _create_batch_prompt_messages(self, game_states: list, main_task: str, available_skills: list) -> list:
        """여러 에이전트의 상태를 받아 하나의 배치 프롬프트를 생성합니다."""
        
        # 각 에이전트의 현재 상황을 문자열로 만듭니다.
        situation_reports = []
        for i, game_state in enumerate(game_states):
            loc = game_state['location']
            player = game_state['player_info']
            party_list = game_state['party_info']['pokemon']
            party_str = ", ".join([f"Lv.{p['level']}" for p in party_list])
            report = (
                f"### Agent {i} State\n"
                f"- Location: Map (Bank {loc['map_bank']}, ID {loc['map_id']})\n"
                f"- Player: ${player['money']}, Badges: {player['johto_badges_count']}\n"
                f"- Party: {game_state['party_info']['count']} Pokémon ({party_str})"
            )
            situation_reports.append(report)

        all_situations = "\n\n".join(situation_reports)
        skill_descriptions = "\n".join([f"- {skill.description}" for skill in available_skills])

        system_prompt = "You are an expert AI playing 'Pokémon Gold'. For each agent, choose the single best action from the given list to achieve the main objective. Respond using the specified format for ALL agents."
        user_prompt = (
            f"### Main Objective\n{main_task}\n\n"
            f"### Current Game States\n{all_situations}\n\n"
            f"### Available Actions\n{skill_descriptions}\n\n"
            "### Instructions\n"
            "1. Analyze each agent's state and the main objective.\n"
            "2. For each agent, choose the single most optimal action from the 'Available Actions' list.\n"
            "3. Provide your decision for every agent in the specified format, starting each on a new line.\n"
            "Format:\n"
            "Agent 0 Decision: [Copy the chosen action description here]\n"
            "Agent 1 Decision: [Copy the chosen action description here]\n"
            "Agent 2 Decision: [Copy the chosen action description here]\n"
            "..."
        )

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    
    def choose_next_skill_batch(self, game_states: list, main_task: str, available_skills: list) -> list:
        """여러 에이전트의 다음 스킬을 한 번의 LLM 호출로 결정합니다."""
        messages = self._create_batch_prompt_messages(game_states, main_task, available_skills)
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

        inputs_tensor = self.tokenizer.apply_chat_template(
            messages,
            add_generation_prompt=True,
            return_tensors="pt"
        ).to(self.model.device)
        
        # 더 긴 응답을 위해 max_new_tokens를 늘려줍니다.
        outputs = self.model.generate(
            input_ids=inputs_tensor,
            max_new_tokens=512, # 에이전트 수에 비례하여 늘려야 할 수 있음
            do_sample=False,
            pad_token_id=self.tokenizer.eos_token_id
        )
        
        prompt_length = inputs_tensor.shape[1]
        response_text = self.tokenizer.decode(outputs[0][prompt_length:], skip_special_tokens=True)
        print(f"LLM 원본 응답 (배치):\n{response_text}")

        # 파싱 로직
        chosen_skills = [None] * len(game_states)
        # "Agent X Decision:" 패턴으로 각 줄을 찾습니다.
        decisions = re.findall(r"Agent (\d+) Decision: (.*)", response_text)

        for agent_idx_str, desc in decisions:
            agent_idx = int(agent_idx_str)
            if agent_idx < len(game_states):
                # 가장 잘 맞는 스킬을 찾습니다.
                best_match_skill = None
                for skill in available_skills:
                    if skill.description in desc.strip():
                        best_match_skill = skill
                        break
                if best_match_skill:
                    chosen_skills[agent_idx] = best_match_skill
        
        # LLM이 선택하지 못한 에이전트는 기본 스킬(예: 첫 번째 스킬)로 대체합니다.
        for i in range(len(chosen_skills)):
            if chosen_skills[i] is None:
                print(f"경고: LLM이 Agent {i}의 스킬을 선택하지 못했습니다. 기본 스킬을 할당합니다.")
                chosen_skills[i] = available_skills[0]
        
        return chosen_skills