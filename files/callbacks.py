import pandas as pd
import os
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.logger import Image
import numpy as np
import torch as th

class EpisodeLogCallback(BaseCallback):
    def __init__(self, log_path: str, verbose=0):
        super(EpisodeLogCallback, self).__init__(verbose)
        self.log_path = log_path
        self.episode_num = 0
        # ë¡œê·¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ì™€ í•¨ê»˜ ìƒˆë¡œ ìƒì„±
        if not os.path.exists(self.log_path):
            pd.DataFrame(columns=[
                'episode', 'total_steps', 'episode_reward', 
                'map_bank', 'map_id', 'pos_x', 'pos_y', 
                'party_level_sum', 'badges', 'money', 'events_completed'
            ]).to_csv(self.log_path, index=False)

    def _on_step(self) -> bool:
        # VecEnvì—ì„œëŠ” donesê°€ ì—¬ëŸ¬ í™˜ê²½ì˜ ì¢…ë£Œ ì—¬ë¶€ë¥¼ ë‹´ì€ ë°°ì—´
        for i, done in enumerate(self.locals['dones']):
            if done:
                self.episode_num += 1
                
                # ì¢…ë£Œëœ í™˜ê²½ì˜ ì •ë³´(info) ê°€ì ¸ì˜¤ê¸°
                info = self.locals['infos'][i]
                
                # ë¡œê·¸ ë°ì´í„° ì •ë¦¬
                log_data = {
                    'episode': self.episode_num,
                    'total_steps': self.num_timesteps,
                    'episode_reward': info.get('episode', {}).get('r', 0),
                    'map_bank': info.get('location', {}).get('map_bank', 0),
                    'map_id': info.get('location', {}).get('map_id', 0),
                    'pos_x': info.get('location', {}).get('x_coord', 0),
                    'pos_y': info.get('location', {}).get('y_coord', 0),
                    'party_level_sum': info.get('party_info', {}).get('party_level_sum', 0),
                    'badges': info.get('player_info', {}).get('johto_badges_count', 0),
                    'money': info.get('player_info', {}).get('money', 0),
                    'events_completed': sum(info.get('event_statuses', {}).values())
                }
                
                # ë¡œê·¸ë¥¼ CSV íŒŒì¼ì— ì¶”ê°€
                df = pd.DataFrame([log_data])
                df.to_csv(self.log_path, mode='a', header=False, index=False)
                
                if self.verbose > 0:
                    print(f"Agent {i} finished episode {self.episode_num}. Log saved to {self.log_path}")

        return True

class BestAgentCallback(BaseCallback):
    """
    ìµœê³  ì„±ê³¼ë¥¼ ë‚´ëŠ” ì—ì´ì „íŠ¸ì˜ ëª¨ë¸ê³¼ ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” ì½œë°±.
    """
    def __init__(self, nav_model_path: str, battle_model_path: str, best_state_path: str, verbose=0):
        super(BestAgentCallback, self).__init__(verbose)
        self.nav_model_path = nav_model_path
        self.battle_model_path = battle_model_path
        self.best_state_path = best_state_path
        
        # ìµœê³  ì ìˆ˜ ì¶”ì  (ìš”ì²­ëœ ìš°ì„ ìˆœìœ„ ê¸°ì¤€)
        self.best_score = {
            "events_completed": -1,
            "episode_reward": -np.inf,
            "badges": -1,
            "party_level_sum": -1,
            "money": -1
        }

    def _is_new_score_better(self, new_score: dict) -> bool:
        """ìƒˆë¡œìš´ ì ìˆ˜ê°€ ê¸°ì¡´ ìµœê³  ì ìˆ˜ë³´ë‹¤ ë‚˜ì€ì§€ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í™•ì¸í•©ë‹ˆë‹¤."""
        priority = ["events_completed", "episode_reward", "badges", "party_level_sum", "money"]
        for key in priority:
            if new_score[key] > self.best_score[key]:
                return True
            if new_score[key] < self.best_score[key]:
                return False
        return False # ëª¨ë“  ì ìˆ˜ê°€ ë™ì¼í•œ ê²½ìš°

    def _on_step(self) -> bool:
        # ì—¬ëŸ¬ í™˜ê²½(ì—ì´ì „íŠ¸)ì„ ìˆœíšŒí•˜ë©° ì—í”¼ì†Œë“œ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸
        for i, done in enumerate(self.locals['dones']):
            if done:
                info = self.locals['infos'][i]
                
                current_score = {
                    "events_completed": sum(info.get('event_statuses', {}).values()),
                    "episode_reward": info.get('episode', {}).get('r', 0),
                    "badges": info.get('player_info', {}).get('johto_badges_count', 0),
                    "party_level_sum": info.get('party_info', {}).get('party_level_sum', 0),
                    "money": info.get('player_info', {}).get('money', 0)
                }

                if self._is_new_score_better(current_score):
                    self.best_score = current_score
                    print("\n" + "="*50)
                    print(f"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ê¸°ë¡ ë‹¬ì„±! (by Agent {i})")
                    print(f"   - ì´ë²¤íŠ¸: {self.best_score['events_completed']}, ë³´ìƒ: {self.best_score['episode_reward']:.2f}, "
                          f"ë°°ì§€: {self.best_score['badges']}, ë ˆë²¨ í•©: {self.best_score['party_level_sum']}")
                    print("   - ìµœê³  ëª¨ë¸ê³¼ ê²Œì„ ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤...")
                    print("="*50 + "\n")

                    # í˜„ì¬ í•™ìŠµ ì¤‘ì¸ ëª¨ë¸ì„ 'ìµœê³  ëª¨ë¸'ë¡œ ì €ì¥
                    # self.modelì€ RecurrentPPO ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ë¦¬í‚´
                    # train_hierarchical.pyì—ì„œ ì–´ë–¤ ëª¨ë¸ì´ learn()ì„ í˜¸ì¶œí–ˆëŠ”ì§€ì— ë”°ë¼ ì €ì¥ë¨
                    if info.get('is_in_battle'):
                        self.model.save(self.battle_model_path)
                    else:
                        self.model.save(self.nav_model_path)
                    
                    # í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ ê²Œì„ ìƒíƒœë¥¼ 'ìµœê³  ìƒíƒœ'ë¡œ ì €ì¥
                    self.training_env.env_method('save_state', self.best_state_path, indices=[i])

        return True

class ImageLogCallback(BaseCallback):
    def __init__(self, frame_interval: int = 1024, verbose=0):
        super(ImageLogCallback, self).__init__(verbose)
        self.frame_interval = frame_interval

    def _on_step(self) -> bool:
        if self.n_calls % self.frame_interval == 0:
            
            obs_dict = self.model._last_obs
          
            image_batch = obs_dict["image"]
       
            latest_frame_batch = image_batch[:, -1:, :, :]
            
            # ì´ì œ 1ì±„ë„ ì´ë¯¸ì§€ë¥¼ TensorBoardì— ì „ë‹¬í•©ë‹ˆë‹¤.
            tb_image = Image(latest_frame_batch.astype(np.uint8), 'NCHW')

            self.logger.record(
                "agent_views/all_agents", 
                tb_image, 
                exclude=("stdout", "log", "csv")
            )
        return True